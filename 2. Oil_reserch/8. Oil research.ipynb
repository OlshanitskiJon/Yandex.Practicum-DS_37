{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b503aee5",
   "metadata": {},
   "source": [
    "# Проект: Машинное обучение в бизнесе\n",
    "\n",
    "\n",
    "## Описание проекта\n",
    "Допустим, вы работаете в добывающей компании «ГлавРосГосНефть». Нужно решить, где бурить новую скважину.\\\n",
    "Шаги для выбора локации обычно такие:\\\n",
    "В избранном регионе собирают характеристики для скважин: качество нефти и объём её запасов;\\\n",
    "Строят модель для предсказания объёма запасов в новых скважинах;\\\n",
    "Выбирают скважины с самыми высокими оценками значений;\\\n",
    "Определяют регион с максимальной суммарной прибылью отобранных скважин.\\\n",
    "Вам предоставлены пробы нефти в трёх регионах. Характеристики для каждой скважины в регионе уже известны. Постройте модель для определения региона, где добыча принесёт наибольшую прибыль. Проанализируйте возможную прибыль и риски техникой *Bootstrap*.\n",
    "\n",
    "## Условия задачи:\n",
    "Для обучения модели подходит только линейная регрессия (остальные — недостаточно предсказуемые).\\\n",
    "При разведке региона исследуют 500 точек, из которых с помощью машинного обучения выбирают 200 лучших для разработки.\\\n",
    "Бюджет на разработку скважин в регионе — 10 млрд рублей.\\\n",
    "При нынешних ценах один баррель сырья приносит 450 рублей дохода. Доход с каждой единицы продукта составляет 450 тыс. рублей, поскольку объём указан в тысячах баррелей.\\\n",
    "После оценки рисков нужно оставить лишь те регионы, в которых вероятность убытков меньше 2.5%. Среди них выбирают регион с наибольшей средней прибылью.\\\n",
    "Данные синтетические: детали контрактов и характеристики месторождений не разглашаются.\n",
    "\n",
    "## План проекта\n",
    "1. [Загрузка и первичное изучение данных.](#start)\n",
    "2. [Обучение и проверка модели для каждого региона](#train)\\\n",
    "    2.1 [Разбивка данных на обучающую и валидационную выборки в соотношении 75:25](#split)\\\n",
    "    2.2 [Обучение модели и получение предсказания на валидационной выборке](#traininig)\\\n",
    "    2.3 [Сохрание предсказания и правильных ответов на валидационной выборке](#save)\\\n",
    "    2.4 [Определение среднего запаса предсказанного сырья и RMSE модели](#mean)\\\n",
    "    2.5 [Анализ результатов](#analisys)\n",
    "3. [Подготовка к расчету прибыли:](#prep_calc)\\\n",
    "    3.1 [Сохранение ключевых значений в отдельных переменных](#save_values)\\\n",
    "    3.2 [Расчет достаточного объёма сырья для безубыточной разработки новой скважины. Сравнение полученного объёма сырья со средним запасом в каждом регионе.](#value_calc)\\\n",
    "    3.3 [Вывод по этапу подготовки расчёта прибыли](#concl_3)\n",
    "4. [Функция для расчёта прибыли по выбранным скважинам и предсказаниям модели](#def_profit)\\\n",
    "    4.1 [Выбор скважин с максимальными значениями предсказаний.](#def_profit)\\\n",
    "    4.2 [Суммирование целевого значения объёма сырья, соответствующее этим предсказаниям.](#def_profit)\\\n",
    "    4.3 [Рассчет прибыли для полученного объёма сырья.](#def_profit)\\\n",
    "    4.4 [Вывод](#concl_4)\n",
    "5. [Расчет рисков и прибыли для каждого региона:](#risks)\\\n",
    "    5.1 [Применение техники Bootstrap с 1000 выборок, чтобы найти распределение прибыли](#risks)\\\n",
    "    5.2 [Нахождение средней прибыли, 95%-й доверительного интервала и риска убытков](#risks)\\\n",
    "    5.3 [Вывод: предложение региона для разработки скважин с обоснованием](#concl_5)\n",
    "6. [Общий вывод](#concl_6)\n",
    "    \n",
    "    \n",
    "## Описание данных\n",
    "Данные геологоразведки трёх регионов находятся в файлах:\n",
    "\n",
    "/datasets/geo_data_0.csv. \\\n",
    "/datasets/geo_data_1.csv. \\\n",
    "/datasets/geo_data_2.csv. \n",
    "\n",
    "`id` — уникальный идентификатор скважины;\\\n",
    "`f0, f1, f2` — три признака точек (неважно, что они означают, но сами признаки значимы);\\\n",
    "`product` — объём запасов в скважине (тыс. баррелей)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8ee0bc",
   "metadata": {},
   "source": [
    "### Загрузка и первичное изучение данных. <a id='start'></a>\n",
    "\n",
    "Необходимые для исследования библиотеки будем хранить здесь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "539c48ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29755d9a",
   "metadata": {},
   "source": [
    "Импортируем данные для исследования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47332982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция пдля импорта данных\n",
    "def import_df(data):\n",
    "    try:\n",
    "        df =  pd.read_csv('C:/Users/79153/Desktop/ya_projects/sprint_11/'+\n",
    "                          str(data)+'.csv')\n",
    "    except:\n",
    "        df = pd.read_csv('/datasets/'+str(data)+'.csv')\n",
    "    return df\n",
    "\n",
    "# параметры импорта данных\n",
    "\n",
    "set_names = ['geo_data_0','geo_data_1','geo_data_2']           # исследумые датасеты\n",
    "\n",
    "# автоматизированный импорт данных в словарь c укороченным именем\n",
    "\n",
    "sets = {}     \n",
    "\n",
    "for i in set_names:\n",
    "    sets[(i)[-1]]= import_df(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83876da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset № 0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   id       100000 non-null  object \n",
      " 1   f0       100000 non-null  float64\n",
      " 2   f1       100000 non-null  float64\n",
      " 3   f2       100000 non-null  float64\n",
      " 4   product  100000 non-null  float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 3.8+ MB\n",
      "---------------------------------------------\n",
      "\n",
      "Dataset № 1\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   id       100000 non-null  object \n",
      " 1   f0       100000 non-null  float64\n",
      " 2   f1       100000 non-null  float64\n",
      " 3   f2       100000 non-null  float64\n",
      " 4   product  100000 non-null  float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 3.8+ MB\n",
      "---------------------------------------------\n",
      "\n",
      "Dataset № 2\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   id       100000 non-null  object \n",
      " 1   f0       100000 non-null  float64\n",
      " 2   f1       100000 non-null  float64\n",
      " 3   f2       100000 non-null  float64\n",
      " 4   product  100000 non-null  float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 3.8+ MB\n",
      "---------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(f'Dataset № {i}')\n",
    "    sets[str(i)].info()\n",
    "    print('---'*15)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10cc534c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset № 0\n",
      "\n",
      "                  f0             f1             f2        product\n",
      "count  100000.000000  100000.000000  100000.000000  100000.000000\n",
      "mean        0.500419       0.250143       2.502647      92.500000\n",
      "std         0.871832       0.504433       3.248248      44.288691\n",
      "min        -1.408605      -0.848218     -12.088328       0.000000\n",
      "25%        -0.072580      -0.200881       0.287748      56.497507\n",
      "50%         0.502360       0.250252       2.515969      91.849972\n",
      "75%         1.073581       0.700646       4.715088     128.564089\n",
      "max         2.362331       1.343769      16.003790     185.364347\n",
      "---------------------------------------------\n",
      "\n",
      "Dataset № 1\n",
      "\n",
      "                  f0             f1             f2        product\n",
      "count  100000.000000  100000.000000  100000.000000  100000.000000\n",
      "mean        1.141296      -4.796579       2.494541      68.825000\n",
      "std         8.965932       5.119872       1.703572      45.944423\n",
      "min       -31.609576     -26.358598      -0.018144       0.000000\n",
      "25%        -6.298551      -8.267985       1.000021      26.953261\n",
      "50%         1.153055      -4.813172       2.011479      57.085625\n",
      "75%         8.621015      -1.332816       3.999904     107.813044\n",
      "max        29.421755      18.734063       5.019721     137.945408\n",
      "---------------------------------------------\n",
      "\n",
      "Dataset № 2\n",
      "\n",
      "                  f0             f1             f2        product\n",
      "count  100000.000000  100000.000000  100000.000000  100000.000000\n",
      "mean        0.002023      -0.002081       2.495128      95.000000\n",
      "std         1.732045       1.730417       3.473445      44.749921\n",
      "min        -8.760004      -7.084020     -11.970335       0.000000\n",
      "25%        -1.162288      -1.174820       0.130359      59.450441\n",
      "50%         0.009424      -0.009482       2.484236      94.925613\n",
      "75%         1.158535       1.163678       4.858794     130.595027\n",
      "max         7.238262       7.844801      16.739402     190.029838\n",
      "---------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(f'Dataset № {i}')\n",
    "    print(\"\")\n",
    "    print(sets[str(i)].describe())\n",
    "    print('---'*15)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9e1435f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset № 0\n",
      "\n",
      "      id        f0        f1        f2     product\n",
      "0  txEyH  0.705745 -0.497823  1.221170  105.280062\n",
      "1  2acmU  1.334711 -0.340164  4.365080   73.037750\n",
      "2  409Wp  1.022732  0.151990  1.419926   85.265647\n",
      "3  iJLyR -0.032172  0.139033  2.978566  168.620776\n",
      "4  Xdl7t  1.988431  0.155413  4.751769  154.036647\n",
      "5  wX4Hy  0.969570  0.489775 -0.735383   64.741541\n",
      "6  tL6pL  0.645075  0.530656  1.780266   49.055285\n",
      "7  BYPU6 -0.400648  0.808337 -5.624670   72.943292\n",
      "8  j9Oui  0.643105 -0.551583  2.372141  113.356160\n",
      "9  OLuZU  2.173381  0.563698  9.441852  127.910945\n",
      "---------------------------------------------\n",
      "\n",
      "Dataset № 1\n",
      "\n",
      "      id         f0         f1        f2     product\n",
      "0  kBEdx -15.001348  -8.276000 -0.005876    3.179103\n",
      "1  62mP7  14.272088  -3.475083  0.999183   26.953261\n",
      "2  vyE1P   6.263187  -5.948386  5.001160  134.766305\n",
      "3  KcrkZ -13.081196 -11.506057  4.999415  137.945408\n",
      "4  AHL4O  12.702195  -8.147433  5.004363  134.766305\n",
      "5  HHckp  -3.327590  -2.205276  3.003647   84.038886\n",
      "6  h5Ujo -11.142655 -10.133399  4.002382  110.992147\n",
      "7  muH9x   4.234715  -0.001354  2.004588   53.906522\n",
      "8  YiRkx  13.355129  -0.332068  4.998647  134.766305\n",
      "9  jG6Gi   1.069227 -11.025667  4.997844  137.945408\n",
      "---------------------------------------------\n",
      "\n",
      "Dataset № 2\n",
      "\n",
      "      id        f0        f1        f2     product\n",
      "0  fwXo0 -1.146987  0.963328 -0.828965   27.758673\n",
      "1  WJtFt  0.262778  0.269839 -2.530187   56.069697\n",
      "2  ovLUW  0.194587  0.289035 -5.586433   62.871910\n",
      "3  q6cA6  2.236060 -0.553760  0.930038  114.572842\n",
      "4  WPMUX -0.515993  1.716266  5.899011  149.600746\n",
      "5  LzZXx -0.758092  0.710691  2.585887   90.222465\n",
      "6  WBHRv -0.574891  0.317727  1.773745   45.641478\n",
      "7  XO8fn -1.906649 -2.458350 -0.177097   72.480640\n",
      "8  ybmQ5  1.776292 -0.279356  3.004156  106.616832\n",
      "9  OilcN -1.214452 -0.439314  5.922514   52.954532\n",
      "---------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(f'Dataset № {i}')\n",
    "    print(\"\")\n",
    "    print(sets[str(i)].head(10))\n",
    "    print('---'*15)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72344923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset № 0\n",
      "Quntity of duplicates: 0\n",
      "---------------------------------------------\n",
      "\n",
      "Dataset № 1\n",
      "Quntity of duplicates: 0\n",
      "---------------------------------------------\n",
      "\n",
      "Dataset № 2\n",
      "Quntity of duplicates: 0\n",
      "---------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(f'Dataset № {i}')\n",
    "    print(f'Quntity of duplicates: {sets[str(i)].duplicated().sum()}')\n",
    "    print('---'*15)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513559ca",
   "metadata": {},
   "source": [
    "### Вывод по первичному осмотру датасетов\n",
    "Можно однозначно сказать:\n",
    "1. Датасеты не содержат пропуски\n",
    "2. Датасеты не содержат дубликаты\n",
    "\n",
    "Судя по максимальным и минимальным значениям `f1`,`f2`,`f2` данные промасштабированы, кроме того адекватно оценить наличие выбросов невозможно так как параметры зашифрованы. Определить степень готовности данных к исследованию затруднительно, при условии, что данные синтетические, будем считать, что дополнительная предобработка данных в данном случае не нужна."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ffd66b",
   "metadata": {},
   "source": [
    "### 2. Обучение и проверка модели для каждого региона <a id='train'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9d466c",
   "metadata": {},
   "source": [
    "Автоматизируем разбиение и обучение модели с помощью функции, а так же сразу выведем интересующие нас метрики   <a id='split'><a id='save'><a id='training'><a id='mean'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fbd1910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitter(df):\n",
    "    # объявим признаки и цели\n",
    "    feature_names = ['f0', 'f1', 'f2']\n",
    "    target_name = ['product']\n",
    "    \n",
    "    feature = df[feature_names]\n",
    "    target = df[target_name]\n",
    "    \n",
    "    # разбивка на выборки\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(feature, target, test_size=0.25, random_state=123)\n",
    "    \n",
    "    # обучение модели\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    predict = model.predict(X_valid)\n",
    "    \n",
    "    # подсчет метрик\n",
    "    predict_mean = predict.mean()\n",
    "    rmse = mean_squared_error(y_valid, predict)**0.5\n",
    "    r2 = r2_score(y_valid,predict)\n",
    "    \n",
    "    # проверка разбивки\n",
    "    print('Train shape:', X_train.shape)\n",
    "    print('Valid shape:', X_valid.shape)\n",
    "    \n",
    "    # вывод метрик\n",
    "    print('Mean facilities: {:.4f}'.format(predict_mean))\n",
    "    print('RMSE модели: {:.4f}'.format(rmse))\n",
    "    print('Сoefficient of determination (R2): {:.4f}'.format(r2))\n",
    "        \n",
    "    return y_valid, predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cea41d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset № 0\n",
      "Train shape: (75000, 3)\n",
      "Valid shape: (25000, 3)\n",
      "Mean facilities: 92.5494\n",
      "RMSE модели: 37.6479\n",
      "Сoefficient of determination (R2): 0.2813\n",
      "---------------------------------------------\n",
      "\n",
      "Dataset № 1\n",
      "Train shape: (75000, 3)\n",
      "Valid shape: (25000, 3)\n",
      "Mean facilities: 69.2800\n",
      "RMSE модели: 0.8954\n",
      "Сoefficient of determination (R2): 0.9996\n",
      "---------------------------------------------\n",
      "\n",
      "Dataset № 2\n",
      "Train shape: (75000, 3)\n",
      "Valid shape: (25000, 3)\n",
      "Mean facilities: 95.0986\n",
      "RMSE модели: 40.1280\n",
      "Сoefficient of determination (R2): 0.1931\n",
      "---------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "valid = {}\n",
    "predict = {}\n",
    "for i in range(3):\n",
    "    print(f'Dataset № {str(i)}')\n",
    "    valid[str(i)], predict[str(i)] = splitter(sets[str(i)])\n",
    "    print('---'*15)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d882d5a8",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "1. Разбивка проведена верно\n",
    "2. Наилучший показатель RMSE и R2 у модели обученной на датасете №1 \n",
    "3. Лучшие средние производственные показатели у датасета №2, но как и у датасета №0 у него очень большое среднее отклонение и крайне низкий коэффициент детерминации\n",
    "\n",
    "Вероятнее всего линейная регрессия не подходит для 2 и 0 датасетов, следует применить более сложную модель обучения, но условия тз не позволяют сделать этого."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5befa74f",
   "metadata": {},
   "source": [
    "### Подготовка к расчету прибыли <a id='prep_calc'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69ce960",
   "metadata": {},
   "source": [
    "Сохраним ключевые значения в отдельных переменных <a id='save_values'></a>\n",
    "- `budget` - бюджет, рубль\n",
    "- `wells` - выбранные скажины, шт.\n",
    "- `research_wells` - исследуемые скважины, шт.\n",
    "- `unit_profit` - доход с одного барелля сырья, рубль"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b2f3166",
   "metadata": {},
   "outputs": [],
   "source": [
    "budget = 10*10**9  \n",
    "wells = 200\n",
    "research_wells = 500\n",
    "unit_profit = 450*10**3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a71c532",
   "metadata": {},
   "source": [
    "Рассчитаем минимальнодостаточный объем для разработки и средний показатель по 200 лучшим скважинам в датасетах. \n",
    "Для расчета используем функцию. <a id='value_calc'></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1a0b16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_value = budget/(wells*unit_profit)\n",
    "\n",
    "def desire(data):\n",
    "    best_200_mean = data['product'].sort_values(ascending=False)[:wells].mean()\n",
    "    if best_200_mean > min_value:\n",
    "        print('Средняя производительность 200 лучших скважин {:.2f}, что удовлетворяет условиям'.format(best_200_mean))\n",
    "    else:\n",
    "        print('Средняя производительность 200 лучших скважин  {:.2f}, что не удовлетворяет условиям'.format(best_200_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53a24a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Минимальный достаточный объем сырья для разработки: 111.11\n",
      "\n",
      "Dataset №0\n",
      "Средняя производительность 200 лучших скважин 184.83, что удовлетворяет условиям\n",
      "\n",
      "Dataset №1\n",
      "Средняя производительность 200 лучших скважин 137.95, что удовлетворяет условиям\n",
      "\n",
      "Dataset №2\n",
      "Средняя производительность 200 лучших скважин 189.55, что удовлетворяет условиям\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Минимальный достаточный объем сырья для разработки: {:.2f}'.format(min_value))\n",
    "print(\"\")\n",
    "for i in sets:\n",
    "    print(f'Dataset №{i}')\n",
    "    desire(sets[i])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddabce48",
   "metadata": {},
   "source": [
    "#### Вывод по этапу подготовки расчёта прибыли <a id='concl_3'></a>\n",
    "Во всех трех датасетах производительность 200 лучших скважин удовлетворяет условиям. Последующая работа будет проводится на всех трех датасетах."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7606eb8a",
   "metadata": {},
   "source": [
    "### Расчёт прибыли по выбранным скважинам и предсказаниям модели <a id='def_profit'></a>\n",
    "Выбор скважин ведется исходя из предсказания, а подсчет по известному целевому признаку, для справки добавим так же вывод прибыли по непосредственно предсказанию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83a97cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def income(preds, target):\n",
    "    target = pd.Series(target['product']).reset_index(drop=True)\n",
    "    preds = pd.Series(*preds.reshape(1,-1))\n",
    "    \n",
    "    # берем из 500 рандомных 200 лучших\n",
    "    sample_preds = preds.sample(n=research_wells, random_state=123)\n",
    "    top_preds =  sample_preds.sort_values(ascending=False)[:wells]\n",
    "    top_targets = target[top_preds.index]\n",
    "    \n",
    "    # подсчет искомых величин\n",
    "    volume = sum(top_targets)\n",
    "    income = volume * unit_profit - budget\n",
    "    volume_pred = sum(top_preds)\n",
    "    income_pred = volume_pred * unit_profit - budget\n",
    "    \n",
    "    # вывод показателей\n",
    "    print('Суммарная целевая производительность: {:.2f}'.format(volume))\n",
    "    print('Суммарная предсказанная производительность: {:.2f}'.format(volume_pred))\n",
    "    print('Прибыль по целевому признаку: {:.2f} млн.р.'.format(income/(10**6)))\n",
    "    print('Прибыль по предсказанию: {:.2f} млн.р.'.format(income_pred/(10**6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44d906d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset № 0\n",
      "Суммарная целевая производительность: 23078.71\n",
      "Суммарная предсказанная производительность: 22655.10\n",
      "Прибыль по целевому признаку: 385.42 млн.р.\n",
      "Прибыль по предсказанию: 194.79 млн.р.\n",
      "---------------------------------------------\n",
      "\n",
      "Dataset № 1\n",
      "Суммарная целевая производительность: 22882.63\n",
      "Суммарная предсказанная производительность: 22883.35\n",
      "Прибыль по целевому признаку: 297.18 млн.р.\n",
      "Прибыль по предсказанию: 297.51 млн.р.\n",
      "---------------------------------------------\n",
      "\n",
      "Dataset № 2\n",
      "Суммарная целевая производительность: 23024.03\n",
      "Суммарная предсказанная производительность: 22810.42\n",
      "Прибыль по целевому признаку: 360.81 млн.р.\n",
      "Прибыль по предсказанию: 264.69 млн.р.\n",
      "---------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(f'Dataset № {i}')\n",
    "    income(predict[str(i)], valid[str(i)])\n",
    "    print('---'*15)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2b9cbd",
   "metadata": {},
   "source": [
    "### Вывод <a id='concl_4'></a>\n",
    "В данном пункте мы расчитали прибыль по прогнозу и известному целевому признаку и убедились, что приведенные ранее метрики были правы - на датасетах №0 и №2 присутствует существенное отклонение по прибыли."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f2a93f",
   "metadata": {},
   "source": [
    "### Расчет рисков и прибыли для каждого региона <a id='risks'></a>\n",
    "Подсчитаем риски и прибыли, применяя *boostrap*. Отбор скважин ведется по предсказанию, а расчет по известной целевой величине."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "185d4f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def risk(target, preds):\n",
    "    \n",
    "    # Заданные условиями параметры\n",
    "    samples = 1000\n",
    "    alpha = 0.05\n",
    "    \n",
    "    incomes = []\n",
    "    \n",
    "    target = pd.Series(target['product']).reset_index(drop=True)\n",
    "    preds = pd.Series(*preds.reshape(1,-1))\n",
    "    \n",
    "    # вынос рандомайзера за пределы цикла\n",
    "    rnd = np.random.RandomState(123)\n",
    "    \n",
    "    for _ in range(samples):\n",
    "        \n",
    "        # берем из 500 рандомных 200 лучших\n",
    "        sample_preds = preds.sample(n=research_wells, replace=True, random_state=rnd)\n",
    "        top_preds =  sample_preds.sort_values(ascending=False)[:wells]\n",
    "        top_targets = target[top_preds.index]\n",
    "    \n",
    "        # подсчет производительности и прибыли\n",
    "        volume = sum(top_targets)\n",
    "        income = volume * unit_profit - budget\n",
    "        # сохранение результата\n",
    "        incomes.append(income)\n",
    "\n",
    "    incomes = pd.Series(incomes)\n",
    "    \n",
    "    # подсчет искомых величин\n",
    "    income_mean = incomes.mean()\n",
    "    int_left = incomes.quantile(q = alpha*0.5)\n",
    "    int_right = incomes.quantile(q = (1 - alpha*0.5))\n",
    "    \n",
    "    # подсчет доли отрицательных прибылей\n",
    "    risk = (incomes < 0).mean()\n",
    "\n",
    "    print('Средняя прибыль {:.2f} , млн. р.'.format(income_mean / 10**6))\n",
    "    print('Доверительный интервал (95%): {:.2f} - {:.2f}, млн. р.'.format(int_left / 10**6, int_right / 10**6))\n",
    "    print('Риск убытка: {:.2f} %'.format(risk * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "780b783c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset № 0\n",
      "Средняя прибыль 477.42 , млн. р.\n",
      "Доверительный интервал (95%): -57.99 - 974.82, млн. р.\n",
      "Риск убытка: 4.10 %\n",
      "---------------------------------------------\n",
      "\n",
      "Dataset № 1\n",
      "Средняя прибыль 479.19 , млн. р.\n",
      "Доверительный интервал (95%): 58.73 - 874.42, млн. р.\n",
      "Риск убытка: 0.90 %\n",
      "---------------------------------------------\n",
      "\n",
      "Dataset № 2\n",
      "Средняя прибыль 343.45 , млн. р.\n",
      "Доверительный интервал (95%): -231.38 - 860.84, млн. р.\n",
      "Риск убытка: 9.90 %\n",
      "---------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(f'Dataset № {i}')\n",
    "    risk(valid[str(i)], predict[str(i)])\n",
    "    print('---'*15)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f6d447",
   "metadata": {},
   "source": [
    "### Вывод: предложение региона для разработки скважин с обоснованием <a id='concl_5'></a>\n",
    "Для разработки рекомендуется регион из датасета №1:\n",
    "1. Данный регион обладает наименьшим риском убытков\n",
    "2. Доверительный интервал прибыли начинается с положительного числа\n",
    "3. Обладает наибольшей средней прибылью из трех регионов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec5f380",
   "metadata": {},
   "source": [
    "### Общий вывод <a id='concl_6'></a>\n",
    "\n",
    "В данной работе полноценная предобработка данных не была проведена, так как данные синтетические и, судя по значениям  предобработка уже была проведена заказчиком, однако на это нет прямого указания в ТЗ. Поэтому предобработка данных ограничилась поиском явных дубликатов и пропусков, так же проведен осмотр данных.\n",
    "\n",
    "Проведено обучение модели *LinearRegression* для каждого региона по отдельности, получены предсказания производительности скважин. При этом выявлено, что обучение на датасетах прошло с различным успехом, наилучшие результаты показала модель обученная на датасете №2\n",
    "\n",
    "В работе был рассчитан минимальнодостаточный объем сырья для безубыточной разработки новой скважины. С помощью функции рассчитана прибыль с каждого региона, а так же рассчитаны риски и доверительные интевалы для датасетов.\n",
    "\n",
    "По итогу работы наиболее перспективным для разаботки является регион из датасета №1, поскольку:\n",
    "1. Данный регион обладает наименьшим риском убытков\n",
    "2. Доверительный интервал прибыли начинается с положительного числа\n",
    "3. Обладает наибольшей средней прибылью из трех регионов\n",
    "\n",
    "Вторым по перспективности регионом можно признать регион №0, так как при умеренном риске убытка 4.1% он предлагает практически такую же среднюю прибыль и доверительный интервал справа выше на 100 млн.р., то есть есть шанс заработать больше чем на регионе №1.\n",
    "\n",
    "Регион №2 следует признать не перспективным ввиду высокого риска убытка."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
